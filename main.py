import requests
from bs4 import BeautifulSoup
import re
import pandas as pd

make_list = ["samsung", "lg", "tcl", "hisense",
             "toshiba", "philips", "sony", "panasonic"]
size_pattern = r"[\d]{2}\"|[\d]{2}\s(inch)"
price_pattern = r"Â£[0-9\,]+\.[0-9]{2}"


def prepare_data(products):
    site = []
    make = []
    condition = []
    priceZ = []
    for product in products:
        make.append(product[0])
        site.append(product[4])
        condition.append(product[3])
        priceZ.append(product[2])
        dict = {"Make": make,
                "Site": site,
                "Condition": condition,
                "Price": priceZ,
                }
        df = pd.DataFrame(dict)
        df.to_csv('AmazonTVData.csv')

    print(make)


def make_match(web_text):
    new_tv_list = []
    for each in web_text:
        tv_list = []
        for make in make_list:
            if make in each[0]:
                tv_list.append(make)
                match_m = re.search(size_pattern, each[0])
                if match_m:
                    tv_list.append(match_m.group())
                else:
                    tv_list.append("")
                match_price = re.search(price_pattern, each[1])
                if match_price:
                    tv_list.append(match_price.group())
                else:
                    tv_list.append("")

                tv_list.append(each[2])
                tv_list.append("Amazon")
                new_tv_list.append(tv_list)
    return new_tv_list


# Set headers to mimic a web browser

def web_scrap():
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}

    for page in range(1, 2):

        # URL of the Amazon page you want to scrape
        amazon_url = f'https://www.amazon.co.uk/s?k=65+inch+tv&page={page}&crid=3Q9RHHJ0DH71W&qid=1681383218&sprefix=65+inch%2Caps%2C494&ref=sr_pg_1'

        # Make a request to the Amazon page and get its HTML content
        amazon_response = requests.get(amazon_url, headers=headers)

        # Create an empty list to store products
        products = []

        # Check if the requests were successful
        if amazon_response.status_code == 200:

            # Parse the HTML content using BeautifulSoup
            amazon_soup = BeautifulSoup(amazon_response.content, 'html.parser')

            # Extract the information you need from the Amazon page
            amazon_products = amazon_soup.find_all(
                'div', {'class': 's-result-item'})
            for product in amazon_products:
                try:
                    name = product.find('h2').text.strip().lower()
                    if '65 inch' not in name:
                        continue
                    price = product.find('span', {'class': 'a-price'}).text.strip()
                    condition = 'new'

                    products.append([name, price, condition])
                    # Do something with the extracted information
                    # print(f"Amazon: {name}, {price}, {condition}")
                except AttributeError:
                    name = ""

            print(make_match(products))
            prepare_data(make_match(products))

        else:
            print("Error making requests to Amazon")
